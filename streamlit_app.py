import streamlit as st
# OpenAI-compatible client used with Hugging Face router
from openai import OpenAI
import json
import re

# ---------------- CONFIG ----------------
st.set_page_config(
    page_title="G√©n√©rateur d'id√©es de projets GenAI", page_icon="‚ùâ", layout="centered"
)

hf_api_key = st.secrets["HF_API_KEY"]

client = OpenAI(base_url="https://router.huggingface.co/v1", api_key=hf_api_key)


# ---------------- FONCTION LLM ----------------
def generer_projets(sujet, nb_projets):

    # prompt = f"""
    # Tu dois r√©pondre UNIQUEMENT par du JSON valide.

    # G√©n√®re exactement {nb_projets} id√©es de projets informatiques
    # sur le th√®me "{sujet}".

    # Format attendu :
    # [
    #   {{
    #     "titre": "",
    #     "description": "",
    #     "complexite": "D√©butant | Interm√©diaire | Avanc√©",
    #     "technologies": []
    #   }}
    # ]
    # """
    prompt = f"""
    Tu dois r√©pondre UNIQUEMENT par du JSON valide.
    Aucun texte, aucune explication hors du JSON.

    G√©n√®re exactement {nb_projets} id√©es de projets informatiques
    sur le th√®me "{sujet}".

    Pour chaque projet :
    - Le titre doit √™tre clair et concret
    - La description doit contenir 3 √† 5 phrases expliquant :
    - l‚Äôobjectif du projet
    - les principales fonctionnalit√©s
    - un cas d‚Äôusage r√©el
    - La complexit√© doit √™tre exactement l‚Äôune des valeurs suivantes :
    "D√©butant", "Interm√©diaire" ou "Avanc√©"
    - La liste des technologies doit contenir 3 √† 6 √©l√©ments pertinents

    Format attendu :
    [
    {{
        "titre": "string",
        "description": "string",
        "complexite": "D√©butant | Interm√©diaire | Avanc√©",
        "technologies": ["string", "string"]
    }}
    ]
    """


    completion = client.chat.completions.create(
        model="meta-llama/Llama-3.1-8B-Instruct:cerebras",
        messages=[
            {"role": "system", "content": "Tu es un g√©n√©rateur JSON strict."},
            {"role": "user", "content": prompt},
        ],
        max_tokens=150 * nb_projets + 300,  # tokens adaptatifs
    )

    contenu = completion.choices[0].message.content.strip()

    if not contenu:
        raise ValueError("R√©ponse vide du mod√®le.")

    if "```" in contenu:
        contenu = contenu.split("```")[1].replace("json", "").strip()

    projets = extraire_json(contenu)

    return projets[:nb_projets]


def extraire_json(contenu):
    match = re.search(r"\[.*\]", contenu, re.DOTALL)
    if not match:
        raise ValueError("Aucun tableau JSON valide trouv√©.")
    return json.loads(match.group())


# ---------------- INTERFACE ----------------
st.title("G√©n√©rateur d‚Äôid√©es de projets")
st.markdown(
    """
Ce g√©n√©rateur utilise un **LLM open-source (Llama 3.1)** pour proposer  
des **id√©es de projets d√©taill√©es avec niveau de complexit√©**.
"""
)
with st.form("form_generation"):
    sujet = st.text_input("Sujet", placeholder="Ex: IA, Cybers√©curit√©, Web, IoT...")
    nb_projets = st.slider("Nombre de projets", min_value=1, max_value=10, value=5)
    submitted = st.form_submit_button("G√©n√©rer")

if submitted:
    if not sujet.strip():
        st.warning("Veuillez entrer un sujet.")
    else:
        with st.spinner("G√©n√©ration en cours..."):
            try:
                projets = generer_projets(sujet, nb_projets)
                st.success(f"{len(projets)} projets g√©n√©r√©s avec succ√®s !")

                for i, p in enumerate(projets, 1):
                    with st.expander(f"üìå Projet {i} : {p['titre']}"):
                        st.write(f"**Description :** {p['description']}")
                        st.write(f"**Complexit√© :** {p['complexite']}")
                        st.write("**Technologies :**")
                        st.write(", ".join(p["technologies"]))

            except Exception as e:
                st.error("Erreur lors de la g√©n√©ration")
                st.code(str(e))